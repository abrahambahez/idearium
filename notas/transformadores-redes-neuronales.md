# transformadores (redes neuronales)
En [[aprendizaje-de-maquinas]], los transformadores son una arquitectura de [[red-neuronal-artificial]] basada en el aprendizaje semi-supervisado.

Los transformadores usan un [[mecanismo-de-atencion-artificial]] y una estrategia llamada positional encoding o codificación posicional, que permite conocer la posición de cada palabra en su secuencia original, expresada en una función sinusoidal que representa el patrón binario en el que está codificada esa posición.

La codificación posicional permite la **paralelización del proceso de entrenamiento** y, por lo tanto, optimiza los recursos y resultados del modelo.

A su vez, hay [[tres-arquitecturas-de-los-transformadores]] que son posibles en función de sus componentes principales: el codificador (*encoder*) y el decodificador (*decoder*).
