---
source: "https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai"
author:
  - "Molly White"
published: 2025-03-14
created: 2025-03-16
description: "The real threat isn’t AI using open knowledge — it’s AI companies killing the projects that make knowledge free"
---
# “Wait, not like that”: Free and open access in the age of generative AI
#clip

The visions of the open access movement have inspired countless people to contribute their work to the commons: a world where “every single human being can freely share in the sum of all knowledge” (Wikimedia), and where “education, culture, and science are equitably shared as a means to benefit humanity” (Creative Commons<sup id="footnote-anchor-1" class="footnote-anchor"><a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/#footnote-1">a</a></sup>).

But there are scenarios that can introduce doubt for those who contribute to free and open projects like the Wikimedia projects, or who independently release their own works under free licenses. I call these “wait, no, not like that” moments.

When a passionate Wikipedian discovers their carefully researched article has been packaged into an e-book and sold on Amazon for someone else’s profit? *Wait, no, not like that*.

When a developer of an open source software project sees a multi-billion dollar tech company rely on their work without contributing anything back? *Wait, no, not like that.*

When a nature photographer discovers their freely licensed wildlife photo was used in an NFT collection minted on an environmentally destructive blockchain? *Wait, no, not like that*.

And perhaps most recently, when a person who publishes their work under a free license discovers that work has been used by tech mega-giants to train extractive, exploitative large language models? ***Wait, no, not like that*.**

The first impulse is often to try to tighten the licensing, maybe by switching away to something like the [Creative Commons’ non-commercial](https://en.wikipedia.org/wiki/Creative_Commons_NonCommercial_license) (and thus, non-free) license. When NFTs enjoyed a moment of popularity in the early 2020s, some artists looked to Creative Commons in hopes that they might declare NFTs fundamentally incompatible with their free licenses (they didn’t<sup id="reference-anchor-1" class="reference-anchor"><a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/#reference-1">1</a></sup>). The same thing happened again with the explosion of generative AI companies training models on CC-licensed works, and some were disappointed to see the group take the stance that, not only do CC licenses not prohibit AI training wholesale, AI training should be considered non-infringing by default from a copyright perspective.<sup id="reference-anchor-2" class="reference-anchor"><a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/#reference-2">2</a></sup>

But the trouble with trying to continually narrow the definitions of “free” is that it is impossible to write a license that will perfectly prohibit each possibility that makes a person go “wait, no, not like that” while retaining the benefits of free and open access. If that is truly what a creator wants, then they are likely better served by a traditional, all rights reserved model in which any prospective reuser must individually negotiate terms with them; but this undermines the purpose of free, and restricts permitted reuse only to those with the time, means, and bargaining power to negotiate on a case by case basis.<sup id="footnote-anchor-2" class="footnote-anchor"><a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/#footnote-2">b</a></sup>

There’s also been an impulse by creators concerned about AI to dramatically limit how people can access their work. Some artists have decided it’s simply not worthwhile to maintain an online gallery of their work when that makes it easily accessible for AI training. Many have implemented restrictive content gates — paywalls, registration-walls, “are you a human”-walls, and similar — to try to fend off scrapers. This too closes off the commons, making it more challenging or expensive for those “every single human beings” described in open access manifestos to access the material that was originally intended to be common goods.

Often by trying to wall off those considered to be bad actors, people wall off the very people they intended to give access to. People who gate their work behind paywalls likely didn’t set out to create works that only the wealthy could access. People who implement registration walls probably didn’t intend for their work to only be available to those willing to put up with the risk of incessant email spam after they relinquish their personal information. People who try to stave off bots with CAPTCHAs asking “are you a human?” probably didn’t mean to limit their material only to abled people<sup id="reference-anchor-7" class="reference-anchor"><a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/#reference-7">7</a></sup> who are willing to abide ever more protracted and irritating riddles.<sup id="reference-anchor-8" class="reference-anchor"><a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/#reference-8">8</a></sup> And people using any of these strategies likely didn’t want people to struggle to even find their work in the first place after the paywalls and regwalls and anti-bot mechanisms thwarted search engine indexers or social media previews.

**Instead of worrying about “wait, not like that”, I think we need to reframe the conversation to “wait, not *only* like that” or “wait, not in ways that threaten open access itself”.** The true threat from AI models training on open access material is not that more people may access knowledge thanks to new modalities. It’s that those models may stifle Wikipedia and other free knowledge repositories, benefiting from the labor, money, and care that goes into supporting them while also bleeding them dry. It’s that trillion dollar companies become the sole arbiters of access to knowledge after subsuming the painstaking work of those who made knowledge free to all, killing those projects in the process.

Irresponsible AI companies are already imposing huge loads on Wikimedia infrastructure, which is costly both from a pure bandwidth perspective, but also because it requires dedicated engineers to maintain and improve systems to handle the massive automated traffic. And AI companies that do not attribute their responses or otherwise provide any pointers back to Wikipedia prevent users from knowing where that material came from, and do not encourage those users to go visit Wikipedia, where they might then sign up as an editor, or donate after seeing a request for support. (This is most AI companies, by the way. Many AI “visionaries” seem perfectly content to promise that artificial superintelligence is just around the corner, but claim that attribution is somehow a permanently unsolvable problem.)

And while I rely on Wikipedia as an example here, the same goes for any website containing freely licensed material, where scraping benefits AI companies at often extreme cost to the content hosts. This isn't just about strain on one individual project, it's about the systematic dismantling of the infrastructure that makes open knowledge possible.

It would be very wise for these companies to immediately begin prioritizing the ongoing health of the commons, so that they do not wind up strangling their golden goose. It would also be very wise for the rest of us to not rely on AI companies to suddenly, miraculously come to their senses or develop a conscience en masse.

Instead, we must ensure that mechanisms are in place to *force* AI companies to engage with these repositories on their creators' terms.

There are ways to do it: models like Wikimedia Enterprise, which welcomes AI companies to use Wikimedia-hosted data, but requires them to do so using paid, high-volume pipes to ensure that they do not clog up the system for everyone else and to make them financially support the extra load they’re placing on the project’s infrastructure. Creative Commons is experimenting with the idea of “[preference signals](https://www.ietf.org/slides/slides-aicontrolws-creative-commons-position-paper-on-preference-signals-00.pdf)” — a non-copyright-based model by which to communicate to AI companies and other entities the terms on which they may or may not reuse CC licensed work.<sup id="footnote-anchor-3" class="footnote-anchor"><a href="https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/#footnote-3">c</a></sup> Everyday people need to be given the tools — both legal and technical — to enforce their own preferences around how their works are used.

The future of free and open access isn't about saying “wait, not like that” — it’s about saying "yes, like that, but under fair terms”. With fair compensation for infrastructure costs. With attribution and avenues by which new people can discover and give back to the underlying commons. With deep respect for the communities that make the commons — and the tools that build off them — possible. Only then can we truly build that world where every single human being can freely share in the sum of all knowledge.